### Table of Contents

1. [Installation](#installation)
2. [Project Motivation](#motivation)
3. [File Descriptions](#files)
4. [Results](#results)
5. [Licensing, Authors, and Acknowledgements](#licensing)

## Installation <a name="installation"></a>

The code should run with no issues using Python version 3.0 or older.
Libraries that were used for the analysis are Pandas, Numpy, Scikit-learn, SQLlchemy, NLTK, RE, Pickle.


## Project Motivation<a name="motivation"></a>

As part of the Udacity Data Scientist Nanodegree, I developed this ETL and ML pipeline that takes messages of disaster responses as inputs and then classifies each message as different categories (multilabel classification).


## File Descriptions <a name="files"></a>

The following files are contained in this repository:
1. process_data.py - ETL pipeline that loads the messages and response categories and preprocesses them so that they are ready for the ML pipeline. The results are saved in a database. 
2. train_classifier.py - Machine Learning pipeline that takes messages and response categories as inputs, tokenizes the messages and outputs a trained and optimized ML model
3. 
4. 
5. 

## Results<a name="results"></a>

The above mentioned scripts contain the results of the analysis. They can be used to classify other disaster messages.

## Licensing, Authors, Acknowledgements<a name="licensing"></a>

I want to give credit to Udacity for the data. Also, I relied on numerous posts on Stack Overflow when stuck with any question. 
I also want to thank the Udacity team for providing this code, the very useful instructions and guidelines for completing this project. 
Otherwise, feel free to use the code here as you would like!
